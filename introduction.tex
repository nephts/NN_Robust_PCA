\section{introduction}

Principal Component Analysis (PCA) is a method for finding the principal components of a set of data points. The principal components of a collection of points in the space $\mathbb{R}^n$ are a sequence of $n$ direction vectors, where the $i^{th}$ vector is the direction of a line that best fits the data while being orthogonal to the first $i-1$ vectors. A best fitting line is defined as one that minimizes the average squared distance from the points to the line. The principal components form an orthonormal basis of the space $\mathbb{R}^n$.

One can think of PCA as fitting a p-dimensional ellipsoid to the data, where each axis of the ellipsoid represents a principal component.
\newline

One of the main applications for PCA is in quantitative finance, where data of large quantities is being reduced to a minimum amount of principal components that still hold the most important information about the data. 
\newline

In specific we look at a modification of PCA which is the Robust Principal Component Analysis. Here our aim is to recover a low rank Matrix $L$ from highly corrupted measurements $M$.
\newline

We start with a data matrix $M \in \mathbb{R}^{n \times n}$ with corrupted entries and try to find a composition into a sum $M = L + S$, where $L$ is a matrix of low rank and $S$ is sparse, which means that a lot of entries are zero. $M$ can be for example a covariance matrix which is by nature symmetric and positive definite.
\newline

In this project our aim is to implement the algorithm "Denise", an algorithm to compute a robust PCA for semidefinite matrices via a deep neuronal network.
\newline

Due to slow computation the usual algorithms for PCA are inefficient in some applications e.g. finance, where instantaneous calculation might be required. Therefore the use of a neuronal network is seen to perform better and can once trained be used to reduce computation times for a given problem.

